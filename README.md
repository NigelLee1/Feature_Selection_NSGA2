# Feature_Selection_NSGA2
minimize the number of features and classification error by using NSGA-II

Feature selection is an important task in machine learning and data mining, which involves identifying a subset of relevant features from a large set of features to improve the performance of a model. NSGA2 as a Multi-objective optimization for feature selection have gained increasing attention in recent years due to the evolutionary nature that performs selection, crossover, and mutation operations to generate new offspring individuals with higher fitness compared to previous generation. In this report, we apply this algorithm to a low-scale dataset and a large-scale dataset, namely “Hillvally” and “Musk1” respectively, the min-min optimization problem was used to solve two objectives: (1) minimizing the number of selected features, and (2) minimizing the classification error on training set of a KNN classifier on the selected features. We evaluate the performance of NSGA2 based on non-dominated sorting rankings and hypervolume of the Pareto fronts.
